---
title: "Forecasted Average Treatment Effects"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Forecasted Average Treatment Effects}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", fig.width = 7, fig.height = 4.5)

suppressPackageStartupMessages({
  if (requireNamespace("fatEstimator", quietly = TRUE)) {
    library(fatEstimator)
  } else if (requireNamespace("devtools", quietly = TRUE) && file.exists("../DESCRIPTION")) {
    # Local dev render: knit from vignettes/ using source in package root
    devtools::load_all("..", quiet = TRUE)
  } else {
    stop("Package 'fatEstimator' is not installed and package source not found at '..'.")
  }

  # Other vignette deps:
  library(dplyr)
  library(tidyr)
  library(ggplot2)
})      
```


The `fatEstimator` package implements the *Forecasted Average Treatment Effect Approach* from Botosaru, Giacomini, and Weidner (2024). This method is designed for settings without a reliable control group, such as universal policy interventions, endogenous treatment adoption, or when traditional difference-in-differences assumptions are not credible. Additionally, the approach can be a useful robustness check for settings with a control group, especially when its validity is questionable or the assumptions of the existing methods are too strong to be credible.

Rather than comparing treated units to untreated ones, the FAT method builds unit-specific forecasts of the counterfactual outcome (i.e., what would have happened without treatment), based only on pre-treatment data. The treatment effect is then estimated as the difference between the observed outcome and this forecast. By focusing on unit-specific forecasts, the method allows for heterogeneous treatment effects, unbalanced panels, and staggered (or individual-specific) treatment adoption.

This vignette walks you through:

- The baseline estimator based on pre-treatment trend forecasting,
- The theoretical motivation and required assumptions,
- And model extensions (covariates, heterogeneity, control groups).


## 1. Estimation Strategy: Baseline Case

Assume that all units are treated at a common time $\tau$. The treatment effect at $h$ periods after treatment is defined as:

$$
\widehat{FAT_h} := \frac{1}{n} \sum_{i \in n} [y_{i \tau + h} - \widehat{y}_{i \tau + h}(0)] \tag{1}
$$

- $Y_{i \tau + h}$ is the observed outcome for unit $i$ in period $\tau + h$,
- $\widehat{Y}_{i \tau + h}(0)$ is the forecasted counterfactual - what would $Y$ have been in the absence of treatment.

This estimator does not require a control group. Instead, the counterfactual $\widehat{Y}_{i,\tau+h}(0)$ is predicted using only pre-treatment observations for unit $i$. 


### 1.1 Forecasting the Counterfactual

To forecast $\widehat{Y}_{i,\tau+h}(0)$, we fit a polynomial time trend model to the unit's pre-treatment outcomes:

Let:

- $T_i = {\tau - R_i + 1, \ldots, \tau}$ be the $R_i$ pre-treatment periods used,
- $b_k(t) = t^k$ be the $k$-th order basis function (e.g., $t$, $t^2$, ...),
- $q_i$ be the chosen polynomial degree.

Then the counterfactual forecast is:

$$
\widehat{y}_{i \tau + h}^{(q_i, R_i)}(0) = \sum_{k=0}^{q_i} \widehat{c}_{ik}^{(q_i, R_i)} (\tau + h)^k \tag{2}
$$

The coefficients $\widehat{c}_{ik}$ are estimated by minimizing squared residuals on the pre-treatment window:

$$
\widehat{c}^{(q_i, R_i)}_i = \arg\min_{c \in \mathbb{R}^{q_i+1}} \sum_{t \in T_i} \left(y_{it} - \sum_{k=0}^{q_i} c_k t^k\right)^2 \tag{3}
$$
This is a simple ordinary least squares regression of $Y_{it}$ on time and its powers (up to $q_i$), using only periods before treatment.

### 1.2. Interpretation and Implementation
- If $q_i = 0$, the forecast is the mean of pre-treatment outcomes.
- If $q_i = 1$, we estimate a linear trend.
- Higher-order $q_i$ allow for quadratic or cubic pre-treatment dynamics.

The choice of $q_i$ and $R_i$ involves a trade-off:

- Smaller $q_i$ → lower variance, but possibly biased if there’s a deterministic trend.
- Larger $q_i$ → more flexible, but may overfit or inflate standard errors.

In practice, we recommend trying a small set of values: $q_i \in {0, 1, 2, 3}$, and choosing $R_i$ as large as possible unless pre-trends suggest instability.

```{r simulate-panel, echo=TRUE, message=FALSE}
# Minimal simulated panel used across examples
library(dplyr); library(tidyr);

# Parameters
n_units <- 20
n_years <- 15
min_year <- 1995
unit_names <- paste0("state", 1:n_units)

data_list <- lapply(unit_names, function(unit) {
  treat_year <- sample(2004:2007, 1)  # Treatment years between 2004 and 2007
  years <- min_year:(min_year + n_years - 1)

  tibble::tibble(
    state = unit,
    Year = years,
    adopt_year = treat_year,
    timeToTreat = Year - treat_year,
    covariate1 = rnorm(n_years, mean = 0, sd = 1),
    covariate2 = rnorm(n_years, mean = 0, sd = 1),
    instrument = lag(covariate1, 2),
    ln_age_mort_rate = 3 + 0.05 * (years - min_year) - 0.2 * (years >= treat_year) +
      0.3 * rnorm(n_years) + 0.5 * rnorm(1)  # base trend + noise + unit FE
  )
})

# Combine into panel
sim_data <- dplyr::bind_rows(data_list)

# Clean up instrument column (remove NA due to lag)
sim_data <- dplyr::group_by(sim_data, state) %>%
  dplyr::mutate(instrument = dplyr::lag(covariate1, 2)) %>%
  dplyr::ungroup()

head(sim_data)
```

```{r fat-estimation, echo=TRUE, message=FALSE}
fat_base <- estimate_fat(
  data                = sim_data,
  unit_var            = "state",
  time_var            = "Year",
  outcome_var         = "ln_age_mort_rate",
  treat_time_var      = "adopt_year",
  degrees             = 0:3,
  horizons            = 1:3,
  se_method           = "analytic",
  beta_estimator      = "none",
  forecast_lag        = 1,          # forecast starts in adoption year
  pretreatment_window = "full"      # use all pre-treatment years available
)

fat_base$results
```

``` {r plot FAT results, echo=FALSE, message=FALSE}
p_fat <- plot_fat_ci(fat_base$results, title = "FAT with 95% CI")
p_fat

```

#### Theoretical Justification
Under suitable conditions on the data generating process (DGP), the forecast $\widehat{y}_{i, \tau + h}(0)$ is **unbiased on average**, i.e.: 
$$
\mathbb{E}[\widehat{Y}_{i, \tau + h}(0)] = \mathbb{E}[Y_{i, \tau + h}(0)]
$$
So the FAT estimator consistently estimates the average treatment effect on the treated (ATT). Botosaru et al. (2024) show that this holds under two general data-generating processes (DGPs):

- **Stationary/Stochastic Trends** (Theorem 1): Forecasts based on convex combinations of past outcomes (e.g., low-order polynomial fits) are asymptotically unbiased without requiring the model to be correct. Forecast validity arises from the law of large numbers and weak dependence in the DGP.
- **Deterministic Trends** (Theorem 2): Forecasts remain unbiased if the true trend lies within the span of the chosen basis functions — e.g., if a degree-$q$ polynomial includes the true trend of order $q_0 \leq q$.

This replaces the "parallel trends" assumption of Difference-in-Differences (DID) with a more flexible condition: forecast validity based on extrapolation from pre-treatment observations.
The FAT framework is particularly useful when pre-periods are short, treatments are staggered, and models are misspecified but still yield unbiased predictions.


#### Summary of Identification Conditions for Baseline FAT
```{r assumptions-table, echo=FALSE, message=FALSE}
knitr::kable(
  data.frame(
    Condition = c(
      "Identification Strategy", "Stationary/Stochastic DGP", "Deterministic DGP", "Trend Specification", "Treatment Timing", "Model Correctness", "Pre-treatment Data", "Forecast Error Behavior"),
    Description = c(
      "Extrapolation from pre-treatment trends",
      "Weighted averages of past outcomes are unbiased (Theorem 1)",
      "True trend lies in the span of forecast basis (Theorem 2)",
      "Low-order polynomial (e.g., degree 0–3) or other basis functions",
      "Staggered adoption allowed",
      "Not required for unbiasedness",
      "Short panels sufficient",
      "Central Limit Theorem applies under weak dependence"
    )
  ),
  align = c("l", "l")
)
```


#### Practical Advice
- Choose $q_i$ (polynomial degree) based on visualization of pre-treatment trends:

  - $q_i = 0$ → constant level,
  - $q_i = 1$ → linear trend,
  - higher $q_i$ for curvature.

- Choose $R_i$ (length of pre-treatment window) by balancing:

  - desire for precision (larger $R_i$),
  - risk of trend instability (smaller $R_i$).
  - The default is $R_i = q_i + 1$, the minimum needed to estimate $q_i$ (`minimal`).
  
- Choose $h$ (forecast horizon) by considering:
  - How long after treatment you expect effects to manifest.
  - Bias increases with $h$ if the forecast model is misspecified.
  - Hence, shorter horizons are preferable unless you can verify robustness.

- Use placebo checks: Apply the FAT estimator to a pretend treatment period before the actual one. If the placebo effect is near zero, this supports the forecast unbiasedness assumption.

- Note limitations of the baseline case:

  - Does not account for unobserved aggregate shocks,
  - Ignores covariates.

#### Accounting for Anticipation Effects
If outcomes respond before formal treatment implementation (e.g., due to anticipation or announcement effects), set $\tau_i$ to the first period of observed outcome change — not necessarily the official treatment date. The FAT method accommodates such redefinitions seamlessly, as long as the pre-treatment forecast window lies entirely before this redefined $\tau_i$. This allows the estimator to remain valid in the presence of early treatment responses.

#### Accommodating Staggered Treatment Timing
The method also supports staggered adoption, where different units are treated at different times. To account for this, define a unit-specific treatment time $\tau_i$ and estimate forecasts relative to each unit’s own $\tau_i$. The package aligns all estimation in event time, allowing for consistent aggregation of forecast errors across units even when treatment timing varies.


## 2. Model-Based FAT Estimation
In settings where treatment effects may depend on additional observed covariates, the FAT framework can be extended to include model-based counterfactual forecasts. These extensions allow for either homogeneous or heterogeneous covariate effects, but they require stronger assumptions than the baseline FAT. The key idea is to augment the trend-based counterfactual model with covariates $x_it$​, either using common (pooled) coefficients or unit-specific slopes.

### 2.1 Homogeneous Coefficients
To incorporate time-varying covariates $x_i$ (e.g., policy drivers or controls), the FAT estimator can be extended to model the counterfactual outcome as:

$$
\widehat{y}_{h}(\beta, y_i, x_i) = x_{i \tau + h}' \widehat{\beta} + \sum_{k=0}^{q_i} \widehat{c}_{ik} (\tau + h)^k \tag{5}
$$

The coefficients $\hat{c_i}$ are unit-specific trend parameters, while $\widehat{\beta}$ is a common coefficient vector estimated across units. The estimation proceeds in two steps:


**Step 1: Estimate the Common Covariate Effect $\beta$**

The coefficient vector $\beta$ summarizes the influence of observed covariates on the outcome and is assumed to be common across units and time. It can be estimated using:

- Pooled OLS, if covariates are exogenous and consistently measured;
- or First-Difference IV (FD-IV) methods, when covariates include endogenous variables such as lagged outcomes (as discussed in footnote 21 of Botosaru et al., 2024).

This step is external to the unit-specific forecast and must rely on valid identification assumptions.


**Step 2: Forecast Unit-Specific Trends on Covariate-Adjusted Outcomes**

Given an estimate $\widehat{\beta}$, the unit-specific polynomial coefficients $\widehat{c_i}$ are optained by regressing the covariate-adjusted outcomes on basis functions over the pre-treatment window $T_i$:

$$
\widehat{c_i}^{(q_i, R_i)} = \arg\min_{c \in \mathbb{R}^{q_i + 1}} \sum_{t \in T_i} \left( y_{it} - x_{it}'\widehat{\beta} - \sum_{k=0}^{q_i} t^k c_k \right)^2 \tag{6}
$$
This step recovers the unit-specific residual dynamics that are not explained by the covariates.

Use homogeneous coefficients when:

- Units are influenced by common shocks or policy drivers,
- Covariates can be reasonably assumed to have the same effect across units,
- Including covariates improves the precision of the forecasted counterfactuals.

#### Requirements and Assumptions
- Covariates $x_it$ must be observed in all pre-treatment periods,
- the model for $\beta$ must be correctly specified and estimated using a valid method,
- the polynomial trend must provide an adequate approximation of residual dynamics,
- unbiasedness of the overall forecast depends on both the accuracy of $\widehat{\beta}$ and the trend specification. 

In the `fatEstimator` package, this option is activated using `beta_estimator = "ols"` or `"iv"` (and set `min_iv_lag` / `max_iv_lag` for IV).

```{r model-based-fat-iv, echo=TRUE, message=FALSE}
fat_iv <- estimate_fat(
  data                = sim_data,
  unit_var            = "state",
  time_var            = "Year",
  outcome_var         = "ln_age_mort_rate",
  treat_time_var      = "adopt_year",
  degrees             = 0:3,
  horizons            = 1:3,
  se_method           = "analytic",
  covariate_vars      = c("covariate1", "covariate2"),
  beta_estimator      = "iv",
  min_iv_lag          = 2,
  max_iv_lag          = 2,
  forecast_lag        = 1,
  pretreatment_window = "full"
)

fat_iv$results

```

``` {r plot FAT results with covariates, echo=FALSE, message=FALSE}
plot_fat_ci(fat_iv$results, title = "FAT with covariates (IV), 95% CI")
```


### 2.2 Heterogeneous Coefficients 

In highly heterogeneous panels, it may be more appropriate to estimate both the time trend and the covariate effects separately for each unit. The unitwise model relaxes the assumption of shared dynamics and fits a full predictive model for each unit. The forecasted counterfactual is then:

$$
\widehat{y}_{i \tau + h}^{(q_i, R_i)}(0) := \sum_{k=0}^{q_i} c_{ik}^{(q_i, R_i)} (\tau + h)^k + \widehat{\beta}^{(i)} x_{i \tau + h} \tag{6}
$$
For each unit $i$, the coefficients are estimated as:

$$
(\widehat{c}^{(q_i, R_i)}, \widehat{\beta}^{(i)}) := \arg\min_{c \in \mathbb{R}^{q_i + 1}, \beta \in \mathbb{R}^{p}} \sum_{t \in T_i} \left( y_{it} - \sum_{k=0}^{q_i} c_k t^k - \beta x_{it} \right)^2 \tag{6.1}
$$

It is important to note that while for the other specifications, "minimal" means we take (degree + 1) most recent pre-treatment times, the unitwise model has (intercept + degree polynomial + length(covariate_vars)) unit-specific β’s, therefore we take (degree + 1 + length(covariate_vars)) pretreatment periods. This is implemented in the package with `beta_estimator = "unitwise"`.

Use heterogeneous coefficients when:

- Units display idiosyncratic dynamics or structural differences,
- Pooled estimation may be misleading,
- You have enough pre-treatment data per unit to estimate covariate effects reliably.

#### Requirements and Assumptions
- Covariates must be available pre-treatment for each unit. 
- Trend and covariate effects must be identifiable from the data for each unit.


```{r model-summary-table, echo=FALSE, message=FALSE}
library(knitr)

# Define the tradeoff table
tradeoff_table <- data.frame(
  beta_estimator = c('"`ols`" / "`iv`"', '"`unitwise`"'),
  Coefficients = c("homogeneous", "heterogeneous"),
  `Suitable` = c("common drivers", "idiosyncratic units"),
  Assumptions = c("model correctly specified", "sufficient pre-treatment observations")
)

# Render as kable
kable(tradeoff_table, align = "llll")
```


```{r fat-unitwise, echo=TRUE, message=FALSE}
fat_unitwise <- estimate_fat(
  data                = sim_data,
  unit_var            = "state",
  time_var            = "Year",
  outcome_var         = "ln_age_mort_rate",
  treat_time_var      = "adopt_year",
  degrees             = 1:2,        # unitwise requires at least linear
  horizons            = 1:3,
  se_method           = "unitwise",
  covariate_vars      = c("covariate1", "covariate2"),
  beta_estimator      = "unitwise",
  forecast_lag        = 0,
  pretreatment_window = "full"   
)

fat_unitwise$results
```
``` {r plot FAT results with heterogeneous covariates, echo=FALSE, message=FALSE}
plot_fat_ci(fat_unitwise$results, title = "Unitwise FAT (heterogeneous), 95% CI")
```


### Note: Stronger Assumptions of the Model-Based FAT
Under the following additional assumptions, the model-based FAT is biased, but remains consistent and asymptotically normal:

  - correct specification of the model
  - availability of a consistent estimator for the homogeneous coefficients,
  - symmetry of the error term for heterogeneous coefficients and covariates that are lagged outcomes. 


## 3 Difference-in-FAT (DFAT)

The baseline FAT approach assumes that post-treatment deviations from forecasts reflect the treatment effect. However, if untreated units are available, and common shocks or structural breaks affect all units post-treatment, a comparison to untreated forecasts can help isolate the treatment effect.

The Difference-in-FAT (DFAT) estimator adjusts for such confounding shocks by comparing forecast errors across treated and control groups:

$$
DFAT_h := FAT_h^{treated} - FAT_h^{control} \tag{7}
$$

This means:

- Forecasts are constructed separately for treated and control units, using only their own pre-treatment data.
- Deviations from the forecast are computed within each group.
- The average post-treatment forecast deviation for the control group is subtracted from that of the treated group.


In DFAT mode, treated and control units are forecast from a common reference year to ensure valid comparison of forecast errors. To do this, in DFAT mode, the package aligns units to the median treated adoption year to ensure common reference timing.

Note: If all treated units adopt in the same year, this median-based alignment has no effect—treated and control units are both aligned to the actual treatment year.
This choice is crucial for avoiding bias. If treated units used their actual adoption year while control units used a shared or arbitrary baseline, the resulting forecast horizons would differ. Such asymmetry would bias the group comparison in Equation (7).


Use DFAT when:

- A valid control group exists, but matching or parallel trends assumptions are not credible.
- The control group helps account for concurrent policy changes, macroeconomic shifts, or other shocks that were not forecasted.
- You want to retain the flexibility of forecast-based counterfactuals, while differencing out structural shocks.

#### Key Assumptions
To ensure interpretability of DFAT, the following conditions must hold:

- Forecasts must be unbiased on average for both treated and control units.
- No interference between groups (i.e., the control group is not indirectly affected by the treatment).
- Treated and control groups face similar structural shocks, so that differencing removes bias.

Note that DFAT does not require the control group to be untreated forever, only that it is untreated during the forecast horizon.

To use DFAT in the `fatEstimator package`:

- Include a logical treated column in your panel dataset.
- Specify `control_group_value = FALSE` to define which units are used as controls.
- The package fits separate models for each group and computes the difference in FATs post-treatment.

```{r sim-data-with-controls, echo=TRUE, message=FALSE}
set.seed(42)

# Parameters
n_units <- 40
n_years <- 10
units <- paste0("state", 1:n_units)
years <- 2000 + 0:(n_years - 1)

# Simulate unit-level data
sim_data_with_controls <- expand.grid(state = units, Year = years)
sim_data_with_controls <- sim_data_with_controls[order(sim_data_with_controls$state,
                                                       sim_data_with_controls$Year), ]

# Half treated, half control
treated_units <- sample(units, n_units / 2)
sim_data_with_controls$treated <- sim_data_with_controls$state %in% treated_units

# Assign adoption year only to treated units
sim_data_with_controls$adopt_year <- ifelse(sim_data_with_controls$treated,
                                            sample(2003:2006, length(treated_units), replace = TRUE)[
                                              match(sim_data_with_controls$state[sim_data_with_controls$treated], treated_units)
                                            ],
                                            NA)

# Time to treatment
sim_data_with_controls$time_to_treat <- sim_data_with_controls$Year - sim_data_with_controls$adopt_year

# Simulate covariates and outcome
sim_data_with_controls$covariate1 <- rnorm(nrow(sim_data_with_controls))
sim_data_with_controls$covariate2 <- rnorm(nrow(sim_data_with_controls))

# Simulate true untreated outcome
sim_data_with_controls$y0 <- with(sim_data_with_controls,
  0.5 * covariate1 - 0.3 * covariate2 + 0.05 * (Year - 2000) +
    rnorm(nrow(sim_data_with_controls), sd = 0.2)
)

# Add treatment effect after adoption for treated units
sim_data_with_controls$ln_age_mort_rate <- sim_data_with_controls$y0 +
  ifelse(sim_data_with_controls$treated &
           !is.na(sim_data_with_controls$adopt_year) &
           sim_data_with_controls$Year > sim_data_with_controls$adopt_year,
         0.25, 0)

head(sim_data_with_controls)
```


```{r dfat-example, echo=TRUE, message=FALSE}
dfat_out <- estimate_fat(
  data                = sim_data_with_controls,
  unit_var            = "state",
  time_var            = "Year",
  outcome_var         = "ln_age_mort_rate",
  treat_time_var      = "adopt_year",
  degrees             = 0:2,
  horizons            = 1:3,
  se_method           = "analytic",
  beta_estimator      = "none",
  control_group_value = FALSE,   # requires 'treated' in data
  forecast_lag        = 0,
  pretreatment_window = "full"
)

dfat_out$results
```

``` {r plot DFAT results, echo=FALSE, message=FALSE}
plot_fat_ci(dfat_out$results, title = "DFAT with 95% CI")
```

``` {r plot DFAT trajectories, echo=FALSE, message=FALSE}
plot_fat_dfat_trajectories(predictions_df = dfat_out$predictions, mode = "dfat")
```

#### Practical Advice
If results differ substantially between FAT and DFAT:

- Consider whether unmodelled shocks are biasing the forecasts,

- Or whether treatment spillovers invalidate the control group as a counterfactual.


## 4. Package Usage

```{r library}
# library(fatEstimator)
```

### 4.1 Application Steps

1. Prepare your data
- Your dataset must be in long-format and contain:
   - a unique unit identifier (e.g., `state`), a time variable (e.g., `Year`), the outcome variable, the treatment time (`adopt_year`) for each unit, and optionally covariates and a `treated` column (for DFAT).
2. Estimate effects with `estimate_fat()`
  - set `degrees`, `horizons`, `forecast_lag`, and `pretreatment_window` to define the forecast model,
  - choose `beta_estimator` (trend-only "`none`", pooled "`ols`"/"`iv`", or "`unitwise`").
3. Interpret results:
   - `$results`: summary of estimates and standard errors across degrees and horizons.
   - `$predictions`: unit-level observed and predicted values for plotting and diagnostic checks.
   - `plot_fat_ci()`: visualize FAT/DFAT + CI ribbons over forecast horizon only.
   - `plot_fat_dfat_trajectories()`: plots average observed and forecasted paths for treated (and control) units.
   

### 4.2 Key Arguments for `estimate_fat()`

```{r key-arguments-table, echo=FALSE, message=FALSE}
knitr::kable(
  data.frame(
    Argument = c("`unit_var`", "`time_var`", "`outcome_var`", "`treat_time_var`",
                 "`degrees`", "`horizons`", "`beta_estimator`", "`control_group_value`", "`se_method`",
                 "`forecast_lag`", "`pretreatment_window`"),
    Description = c(
      "Unique unit identifier (e.g., municipality ID)",
      "Time index (e.g., year)",
      "Variable to forecast (e.g., net debt, mortality)",
      "Treatment adoption year (unit-specific) (e.g., `adopt_year`)",
      "Polynomial degrees for trend fitting (e.g., `0:3`)",
      "Forecast horizons post-treatment (e.g., `1:5`)",
      "`\"none\"` (default), `\"ols\"`, `\"iv\"`, or `\"unitwise\"`",
      "Set to `FALSE` for DFAT (requires `treated` column)",
      "`\"analytic\"`, `\"bootstrap\"`, `\"clustered\"`, or `\"unitwise\"`",
      "Periods to wait after treatment before forecasting (default = 1; 1 year after treatment year)",
      "`\"full\"` or `\"minimal\"` pre-treatment fit window"
    )
  ),
  align = c("l", "l")
)

```

### 4.3 Standard Errors and Inference

Valid inference in the FAT framework relies on the distribution of forecast errors. Under the assumptions outlined in Botosaru et al. (2024), the FAT estimator is:

- **Consistent**: Forecasts are unbiased on average for untreated potential outcomes.
- **Asymptotically Normal**: The average forecast error converges to a normal distribution under weak dependence across units.

The package currently supports several ways of computing standard errors, depending on the estimation context and data structure:

| Method       | Description                                                                 |
|--------------|-----------------------------------------------------------------------------|
| `"analytic"` | Sample standard deviation of forecast errors, divided by √N.                |
| `"bootstrap"`| Resampling units with replacement to estimate variability.                  |
| `"clustered"`| Computes clustered standard errors (e.g. by region or group).               |
| `"unitwise"` | Computes variability across units using unit-specific models (unitwise case only). |
| *(planned)*  | `"robust"` (to be added): heteroskedasticity-robust inference.              |

You can choose the method by setting `se_type` in `estimate_fat()`.

#### Practical Advice

- Use `"bootstrap"` or `"clustered"` if independence across units may be violated.
- Use `"unitwise"` for heterogeneously estimated models where analytic pooling is not meaningful.
- Future updates may include `"robust"` to account for heteroskedasticity.


### 4.4 Robustness and Placebo Checks
The quality of FAT estimates hinges on the validity of the forecasting model. Researchers are strongly encouraged to assess robustness using:

**Placebo Treatments**

- Apply the FAT estimator using a pretend treatment year before the actual intervention.
- If significant “effects” are found pre-treatment, this suggests that the model may be misspecified.
- This is especially important in the presence of anticipatory behavior or non-stationary noise.


```{r placebo-check, echo=TRUE, message=FALSE}
placebo_out <- estimate_placebo_fat(
  data                = sim_data,
  unit_var            = "state",
  time_var            = "Year",
  outcome_var         = "ln_age_mort_rate",
  treat_time_var      = "adopt_year",
  degrees             = 0:3,
  horizons            = 1:3,
  p_lag               = 2,  # default placebo lag
  se_method           = "analytic",
  beta_estimator      = "none",
  forecast_lag        = 1,
  pretreatment_window = "full"
)

placebo_out$results
```
``` {r plot Placebo results, echo=FALSE, message=FALSE}
plot_fat_ci(placebo_out$results, title = "Placebo FAT (lag = 2) with 95% CI")
```

**Other checks**

- Visualize the pre-treatment fit by plotting or using `plot_fat_dfat_trajectories()` after estimating the `$predictions` object.

- Check sensitivity to polinomial degree by re-estimate using different degrees \( q_i \). (Use domain knowledge or visual inspection to guide degree selection.)


### 4.5 Interpretation and Limitations

FAT can recover causal ATT if forecasts are valid, handle staggered adoption and short panels, and avoid reliance on external controls.
FAT cannot guarantee unbiasedness without validation, absorb unobserved shocks unless differenced (DFAT), or separate anticipation without careful timing choices.

FAT trades assumptions about other units for assumptions about how each unit would have evolved in the absence of treatment. Its reliability depends on how predictable the untreated path really is, therefore:

- Justify the choice of forecast model (degree, covariates),
- Verify model fit pre-treatment,
- Run placebo checks to assess forecast validity,
- Avoid extrapolating far beyond the pre-treatment period.


# References

Botosaru, I., Giacomini, R., & Weidner, M. (2024). Forecasted Average Treatment Effects in the Absence of a Control Group. Journal / arXiv, 2024.
